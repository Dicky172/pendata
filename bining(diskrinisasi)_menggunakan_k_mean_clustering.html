
<!DOCTYPE html>


<html lang="en" data-content_root="./" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>üìò Diskretisasi dan Perbandingan Model Naive Bayes dan Decision Tree untuk Klasifikasi Data Iris &#8212; My sample book</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="_static/styles/theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="_static/styles/bootstrap.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="_static/styles/pydata-sphinx-theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />

  
  <link href="_static/vendor/fontawesome/6.5.2/css/all.min.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.5.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.5.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.5.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="_static/pygments.css?v=fa44fd50" />
    <link rel="stylesheet" type="text/css" href="_static/styles/sphinx-book-theme.css?v=eba8b062" />
    <link rel="stylesheet" type="text/css" href="_static/togglebutton.css?v=13237357" />
    <link rel="stylesheet" type="text/css" href="_static/copybutton.css?v=76b2166b" />
    <link rel="stylesheet" type="text/css" href="_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css?v=be8a1c11" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-thebe.css?v=4fa983c6" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-design.min.css?v=95c83b7e" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b" />
<link rel="preload" as="script" href="_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b" />
  <script src="_static/vendor/fontawesome/6.5.2/js/all.min.js?digest=dfe6caa3a7d634c4db9b"></script>

    <script src="_static/documentation_options.js?v=9eb32ce0"></script>
    <script src="_static/doctools.js?v=9a2dae69"></script>
    <script src="_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="_static/clipboard.min.js?v=a7894cd8"></script>
    <script src="_static/copybutton.js?v=f281be69"></script>
    <script src="_static/scripts/sphinx-book-theme.js?v=887ef09a"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="_static/togglebutton.js?v=4a39c7ea"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="_static/design-tabs.js?v=f930bc37"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script async="async" src="_static/sphinx-thebe.js?v=c100c467"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'bining(diskrinisasi)_menggunakan_k_mean_clustering';</script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="prev" title="üå≥ Penjelasan tentang Decision Tree &amp; Information Gain" href="decision_tree.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <div id="pst-skip-link" class="skip-link d-print-none"><a href="#main-content">Skip to main content</a></div>
  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>Back to top</button>

  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-primary-sidebar-checkbox"/>
  <label class="overlay overlay-primary" for="pst-primary-sidebar-checkbox"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-secondary-sidebar-checkbox"/>
  <label class="overlay overlay-secondary" for="pst-secondary-sidebar-checkbox"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search this book..."
         aria-label="Search this book..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>

  <div class="pst-async-banner-revealer d-none">
  <aside id="bd-header-version-warning" class="d-none d-print-none" aria-label="Version warning"></aside>
</div>

  
    <header class="bd-header navbar navbar-expand-lg bd-navbar d-print-none">
    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">

  
    
  

<a class="navbar-brand logo" href="intro.html">
  
  
  
  
  
    
    
      
    
    
    <img src="_static/logosaya.jpg" class="logo__image only-light" alt="My sample book - Home"/>
    <script>document.write(`<img src="_static/logosaya.jpg" class="logo__image only-dark" alt="My sample book - Home"/>`);</script>
  
  
</a></div>
        <div class="sidebar-primary-item">

 <script>
 document.write(`
   <button class="btn search-button-field search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass"></i>
    <span class="search-button__default-text">Search</span>
    <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
   </button>
 `);
 </script></div>
        <div class="sidebar-primary-item"><nav class="bd-links bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="intro.html">
                    intro
                </a>
            </li>
        </ul>
        <ul class="current nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="myintro.html">my introdoction</a></li>
<li class="toctree-l1"><a class="reference internal" href="pendat1.html">Data Understanding</a></li>
<li class="toctree-l1"><a class="reference internal" href="LOF.html">LOF (Local Outlier Factor)</a></li>

<li class="toctree-l1"><a class="reference internal" href="naive_byass.html">Naive Baiyes</a></li>
<li class="toctree-l1"><a class="reference internal" href="Uts.html">üîç Tahap 1: Pemahaman Data (Data Understanding)</a></li>






<li class="toctree-l1"><a class="reference internal" href="k_mean.html">üìä K-Means Clustering pada Dataset Iriss</a></li>
<li class="toctree-l1"><a class="reference internal" href="decision_tree.html">üå≥ Penjelasan tentang Decision Tree &amp; Information Gain</a></li>
<li class="toctree-l1 current active"><a class="current reference internal" href="#">üìò Diskretisasi dan Perbandingan Model Naive Bayes dan Decision Tree untuk Klasifikasi Data Iris</a></li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main" role="main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article d-print-none">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><button class="sidebar-toggle primary-toggle btn btn-sm" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</button></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-source-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Source repositories">
    <i class="fab fa-github"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://github.com/executablebooks/jupyter-book" target="_blank"
   class="btn btn-sm btn-source-repository-button dropdown-item"
   title="Source repository"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="btn__text-container">Repository</span>
</a>
</li>
      
      
      
      
      <li><a href="https://github.com/executablebooks/jupyter-book/issues/new?title=Issue%20on%20page%20%2Fbining(diskrinisasi)_menggunakan_k_mean_clustering.html&body=Your%20issue%20content%20here." target="_blank"
   class="btn btn-sm btn-source-issues-button dropdown-item"
   title="Open an issue"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="btn__text-container">Open issue</span>
</a>
</li>
      
  </ul>
</div>






<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="_sources/bining(diskrinisasi)_menggunakan_k_mean_clustering.ipynb" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.ipynb</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>



<script>
document.write(`
  <button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="theme-switch fa-solid fa-sun fa-lg" data-mode="light"></i>
    <i class="theme-switch fa-solid fa-moon fa-lg" data-mode="dark"></i>
    <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"></i>
  </button>
`);
</script>


<script>
document.write(`
  <button class="btn btn-sm pst-navbar-icon search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
  </button>
`);
</script>
<button class="sidebar-toggle secondary-toggle btn btn-sm" title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</button>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>üìò Diskretisasi dan Perbandingan Model Naive Bayes dan Decision Tree untuk Klasifikasi Data Iris</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#pendahuluan">üåü Pendahuluan</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#apa-itu-diskretisasi">üîç Apa itu Diskretisasi?</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#manfaat-diskretisasi">‚ú® Manfaat Diskretisasi:</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#langkah-langkah-eksperimen">üß≠ Langkah-Langkah Eksperimen</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#mengubah-data-iris-menjadi-kategorikal-diskretisasi">1. üì• Mengubah Data Iris Menjadi Kategorikal (Diskretisasi)</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#klasifikasi-data-asli-dan-data-diskret">2. ü§ñ Klasifikasi Data Asli dan Data Diskret</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#membandingkan-performa-model">3. üìä Membandingkan Performa Model</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#kesimpulan-yang-diharapkan">üéØ Kesimpulan yang Diharapkan</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#clustering-untuk-class-sepal-lenght">clustering untuk class sepal lenght</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#menggabungkan-data-hasil-cluster-dengan-data-original">menggabungkan data hasil cluster dengan data original</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#clustering-untuk-clas-sisa">clustering untuk clas sisa</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#klasifikasi-data-yang-sudah-di-diskritisasi-dengan-menggunakan-metode-naive-baiyes-dan-decision-tree">klasifikasi data yang sudah di diskritisasi dengan menggunakan metode naive baiyes dan decision tree</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#klasifikasi-dengan-naive-baiyes">klasifikasi dengan naive baiyes</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#klasifikasi-dengan-decision-tree">klasifikasi dengan decision tree</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#klasifikasi-data-dengan-data-asli-data-yang-belum-di-diskritisasi-menggunakan-metode-naive-baiyes-dan-decision-tree">klasifikasi data dengan data asli(data yang belum di diskritisasi) menggunakan metode naive baiyes dan decision tree</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id1">klasifikasi dengan naive baiyes</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id2">klasifikasi dengan decision tree</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#perbandingan-performa-atara-model-naive-baiyes-dan-decision-tree-untuk-klasifikasi-data-yang-sudah-di-diskritisasi">perbandingan performa atara model naive baiyes dan decision tree  untuk klasifikasi data yang sudah di diskritisasi</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#perbandingan-performa-atara-model-naive-baiyes-dan-decision-tree-untuk-klasifikasi-data-original">perbandingan performa atara model naive baiyes dan decision tree  untuk klasifikasi data original</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#kesimpulan-visualisasi-performa-model-klasifikasi-pada-dataset-iris">üìä Kesimpulan Visualisasi Performa Model Klasifikasi pada Dataset Iris</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#perbandingan-naive-bayes-vs-decision-tree">üîç Perbandingan Naive Bayes vs Decision Tree</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#data-asli-kontinu">üü¶ Data Asli (Kontinu)</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#data-diskret-diskretisasi-dengan-k-means">üü© Data Diskret (Diskretisasi dengan K-Means)</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#kesimpulan-akhir">‚úÖ Kesimpulan Akhir</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#rekomendasi">üìå Rekomendasi</a></li>
</ul>
</li>
</ul>
            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <section class="tex2jax_ignore mathjax_ignore" id="diskretisasi-dan-perbandingan-model-naive-bayes-dan-decision-tree-untuk-klasifikasi-data-iris">
<h1>üìò Diskretisasi dan Perbandingan Model Naive Bayes dan Decision Tree untuk Klasifikasi Data Iris<a class="headerlink" href="#diskretisasi-dan-perbandingan-model-naive-bayes-dan-decision-tree-untuk-klasifikasi-data-iris" title="Link to this heading">#</a></h1>
<section id="pendahuluan">
<h2>üåü Pendahuluan<a class="headerlink" href="#pendahuluan" title="Link to this heading">#</a></h2>
<p>Pada eksperimen ini, kita akan mengeksplorasi bagaimana proses <strong>diskretisasi menggunakan K-Means</strong> dapat memengaruhi performa dua algoritma klasifikasi yang populer, yaitu <strong>Naive Bayes</strong> dan <strong>Decision Tree</strong>. Kita akan menggunakan dataset terkenal, yaitu <strong>Iris dataset</strong>, yang terdiri dari fitur-fitur numerik seperti panjang dan lebar kelopak bunga.</p>
</section>
<hr class="docutils" />
<section id="apa-itu-diskretisasi">
<h2>üîç Apa itu Diskretisasi?<a class="headerlink" href="#apa-itu-diskretisasi" title="Link to this heading">#</a></h2>
<p><strong>Diskretisasi</strong> adalah proses mengubah data <strong>numerik kontinu</strong> menjadi data <strong>kategori (diskrit)</strong>. Misalnya, data panjang kelopak yang awalnya berupa angka seperti <code class="docutils literal notranslate"><span class="pre">4.3</span></code>, <code class="docutils literal notranslate"><span class="pre">5.1</span></code>, dan <code class="docutils literal notranslate"><span class="pre">6.7</span></code>, akan diubah menjadi kelompok seperti <code class="docutils literal notranslate"><span class="pre">Pendek</span></code>, <code class="docutils literal notranslate"><span class="pre">Sedang</span></code>, dan <code class="docutils literal notranslate"><span class="pre">Panjang</span></code>.</p>
<section id="manfaat-diskretisasi">
<h3>‚ú® Manfaat Diskretisasi:<a class="headerlink" href="#manfaat-diskretisasi" title="Link to this heading">#</a></h3>
<ul class="simple">
<li><p><strong>Menyederhanakan data</strong> ‚Üí lebih mudah diinterpretasi.</p></li>
<li><p><strong>Mengurangi noise</strong> ‚Üí meminimalkan variasi kecil yang tidak relevan.</p></li>
<li><p><strong>Memungkinkan penggunaan algoritma tertentu</strong> seperti <strong>Naive Bayes</strong>, yang bekerja lebih baik pada data kategori.</p></li>
<li><p><strong>Membuka peluang analisis pola berdasarkan kelompok</strong>.</p></li>
</ul>
</section>
</section>
<hr class="docutils" />
<section id="langkah-langkah-eksperimen">
<h2>üß≠ Langkah-Langkah Eksperimen<a class="headerlink" href="#langkah-langkah-eksperimen" title="Link to this heading">#</a></h2>
<section id="mengubah-data-iris-menjadi-kategorikal-diskretisasi">
<h3>1. üì• Mengubah Data Iris Menjadi Kategorikal (Diskretisasi)<a class="headerlink" href="#mengubah-data-iris-menjadi-kategorikal-diskretisasi" title="Link to this heading">#</a></h3>
<ul class="simple">
<li><p>Dataset Iris memiliki fitur numerik.</p></li>
<li><p>Setiap fitur akan diproses secara terpisah menggunakan <strong>K-Means clustering</strong> untuk dikelompokkan menjadi sejumlah kategori (biasanya 3).</p></li>
<li><p>Nilai asli (misalnya 5.7 cm) akan diganti dengan label klaster (misalnya 0, 1, atau 2).</p></li>
<li><p>Hasilnya adalah dataset baru dengan data kategorikal.</p></li>
</ul>
<blockquote>
<div><p>üìå Tujuan dari langkah ini adalah untuk melihat bagaimana model Naive Bayes dan Decision Tree berperforma saat bekerja dengan data diskret hasil klasterisasi.</p>
</div></blockquote>
</section>
<hr class="docutils" />
<section id="klasifikasi-data-asli-dan-data-diskret">
<h3>2. ü§ñ Klasifikasi Data Asli dan Data Diskret<a class="headerlink" href="#klasifikasi-data-asli-dan-data-diskret" title="Link to this heading">#</a></h3>
<p>Kita akan melatih dan menguji dua jenis model klasifikasi:</p>
<ul class="simple">
<li><p><strong>Naive Bayes</strong></p></li>
<li><p><strong>Decision Tree</strong></p></li>
</ul>
<p>Keduanya akan dievaluasi dalam <strong>dua kondisi berbeda</strong>:</p>
<div class="pst-scrollable-table-container"><table class="table">
<thead>
<tr class="row-odd"><th class="head"><p>Kondisi</p></th>
<th class="head"><p>Jenis Data</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>Kondisi Pertama</p></td>
<td><p>Data asli (numerik)</p></td>
</tr>
<tr class="row-odd"><td><p>Kondisi Kedua</p></td>
<td><p>Data hasil diskretisasi (kategori)</p></td>
</tr>
</tbody>
</table>
</div>
<blockquote>
<div><p>Tujuannya adalah untuk melihat apakah diskretisasi berdampak pada performa masing-masing model.</p>
</div></blockquote>
</section>
<hr class="docutils" />
<section id="membandingkan-performa-model">
<h3>3. üìä Membandingkan Performa Model<a class="headerlink" href="#membandingkan-performa-model" title="Link to this heading">#</a></h3>
<p>Setelah proses pelatihan dan pengujian selesai, kita akan membandingkan performa kedua model menggunakan metrik evaluasi:</p>
<ul class="simple">
<li><p><strong>Accuracy</strong></p></li>
<li><p><strong>Precision</strong></p></li>
<li><p><strong>Recall</strong></p></li>
<li><p><strong>F1-Score</strong></p></li>
</ul>
<p>Kita akan menampilkan hasilnya dalam bentuk grafik agar mudah dilihat dan dianalisis.</p>
<blockquote>
<div><p>üîç Dari perbandingan ini, kita akan tahu model mana yang:</p>
<ul class="simple">
<li><p>Lebih cocok untuk data numerik</p></li>
<li><p>Lebih optimal saat data sudah didiskretisasi</p></li>
</ul>
</div></blockquote>
</section>
</section>
<hr class="docutils" />
<section id="kesimpulan-yang-diharapkan">
<h2>üéØ Kesimpulan yang Diharapkan<a class="headerlink" href="#kesimpulan-yang-diharapkan" title="Link to this heading">#</a></h2>
<p>Dengan eksperimen ini, kamu akan mendapatkan wawasan tentang:</p>
<ul class="simple">
<li><p>Pengaruh diskretisasi terhadap performa model klasifikasi.</p></li>
<li><p>Kapan harus menggunakan Naive Bayes atau Decision Tree.</p></li>
<li><p>Bagaimana K-Means bisa digunakan tidak hanya untuk clustering, tetapi juga sebagai alat bantu preprocessing.</p></li>
</ul>
<hr class="docutils" />
<p>Silakan lanjutkan ke bagian implementasi kode di bawah ini untuk melihat semua langkah di atas diterapkan secara langsung! üöÄ</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>

<span class="c1"># Baca file CSV</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">&#39;iris-full.csv&#39;</span><span class="p">)</span>

<span class="c1">#menghapus klom selain sepal lenght</span>
<span class="n">df_filtered</span> <span class="o">=</span> <span class="n">df</span><span class="p">[[</span><span class="s1">&#39;Class&#39;</span><span class="p">,</span> <span class="s1">&#39;sepal length&#39;</span><span class="p">]]</span>

<span class="c1"># Tampilkan 5 baris awal</span>
<span class="nb">print</span><span class="p">(</span><span class="n">df</span><span class="o">.</span><span class="n">head</span><span class="p">())</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output traceback highlight-ipythontb notranslate"><div class="highlight"><pre><span></span><span class="gt">------------------------------------------------</span>
<span class="ne">FileNotFoundError</span>Traceback (most recent call last)
<span class="n">Cell</span> <span class="n">In</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">line</span> <span class="mi">4</span>
<span class="g g-Whitespace">      </span><span class="mi">1</span> <span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="g g-Whitespace">      </span><span class="mi">3</span> <span class="c1"># Baca file CSV</span>
<span class="ne">----&gt; </span><span class="mi">4</span> <span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">&#39;iris-full.csv&#39;</span><span class="p">)</span>
<span class="g g-Whitespace">      </span><span class="mi">6</span> <span class="c1">#menghapus klom selain sepal lenght</span>
<span class="g g-Whitespace">      </span><span class="mi">7</span> <span class="n">df_filtered</span> <span class="o">=</span> <span class="n">df</span><span class="p">[[</span><span class="s1">&#39;Class&#39;</span><span class="p">,</span> <span class="s1">&#39;sepal length&#39;</span><span class="p">]]</span>

<span class="nn">File ~\AppData\Local\Programs\Python\Python312\Lib\site-packages\pandas\io\parsers\readers.py:1026,</span> in <span class="ni">read_csv</span><span class="nt">(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)</span>
<span class="g g-Whitespace">   </span><span class="mi">1013</span> <span class="n">kwds_defaults</span> <span class="o">=</span> <span class="n">_refine_defaults_read</span><span class="p">(</span>
<span class="g g-Whitespace">   </span><span class="mi">1014</span>     <span class="n">dialect</span><span class="p">,</span>
<span class="g g-Whitespace">   </span><span class="mi">1015</span>     <span class="n">delimiter</span><span class="p">,</span>
   <span class="p">(</span><span class="o">...</span><span class="p">)</span>
<span class="g g-Whitespace">   </span><span class="mi">1022</span>     <span class="n">dtype_backend</span><span class="o">=</span><span class="n">dtype_backend</span><span class="p">,</span>
<span class="g g-Whitespace">   </span><span class="mi">1023</span> <span class="p">)</span>
<span class="g g-Whitespace">   </span><span class="mi">1024</span> <span class="n">kwds</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">kwds_defaults</span><span class="p">)</span>
<span class="ne">-&gt; </span><span class="mi">1026</span> <span class="k">return</span> <span class="n">_read</span><span class="p">(</span><span class="n">filepath_or_buffer</span><span class="p">,</span> <span class="n">kwds</span><span class="p">)</span>

<span class="nn">File ~\AppData\Local\Programs\Python\Python312\Lib\site-packages\pandas\io\parsers\readers.py:620,</span> in <span class="ni">_read</span><span class="nt">(filepath_or_buffer, kwds)</span>
<span class="g g-Whitespace">    </span><span class="mi">617</span> <span class="n">_validate_names</span><span class="p">(</span><span class="n">kwds</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;names&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">))</span>
<span class="g g-Whitespace">    </span><span class="mi">619</span> <span class="c1"># Create the parser.</span>
<span class="ne">--&gt; </span><span class="mi">620</span> <span class="n">parser</span> <span class="o">=</span> <span class="n">TextFileReader</span><span class="p">(</span><span class="n">filepath_or_buffer</span><span class="p">,</span> <span class="o">**</span><span class="n">kwds</span><span class="p">)</span>
<span class="g g-Whitespace">    </span><span class="mi">622</span> <span class="k">if</span> <span class="n">chunksize</span> <span class="ow">or</span> <span class="n">iterator</span><span class="p">:</span>
<span class="g g-Whitespace">    </span><span class="mi">623</span>     <span class="k">return</span> <span class="n">parser</span>

<span class="nn">File ~\AppData\Local\Programs\Python\Python312\Lib\site-packages\pandas\io\parsers\readers.py:1620,</span> in <span class="ni">TextFileReader.__init__</span><span class="nt">(self, f, engine, **kwds)</span>
<span class="g g-Whitespace">   </span><span class="mi">1617</span>     <span class="bp">self</span><span class="o">.</span><span class="n">options</span><span class="p">[</span><span class="s2">&quot;has_index_names&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">kwds</span><span class="p">[</span><span class="s2">&quot;has_index_names&quot;</span><span class="p">]</span>
<span class="g g-Whitespace">   </span><span class="mi">1619</span> <span class="bp">self</span><span class="o">.</span><span class="n">handles</span><span class="p">:</span> <span class="n">IOHandles</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span>
<span class="ne">-&gt; </span><span class="mi">1620</span> <span class="bp">self</span><span class="o">.</span><span class="n">_engine</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_make_engine</span><span class="p">(</span><span class="n">f</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">engine</span><span class="p">)</span>

<span class="nn">File ~\AppData\Local\Programs\Python\Python312\Lib\site-packages\pandas\io\parsers\readers.py:1880,</span> in <span class="ni">TextFileReader._make_engine</span><span class="nt">(self, f, engine)</span>
<span class="g g-Whitespace">   </span><span class="mi">1878</span>     <span class="k">if</span> <span class="s2">&quot;b&quot;</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">mode</span><span class="p">:</span>
<span class="g g-Whitespace">   </span><span class="mi">1879</span>         <span class="n">mode</span> <span class="o">+=</span> <span class="s2">&quot;b&quot;</span>
<span class="ne">-&gt; </span><span class="mi">1880</span> <span class="bp">self</span><span class="o">.</span><span class="n">handles</span> <span class="o">=</span> <span class="n">get_handle</span><span class="p">(</span>
<span class="g g-Whitespace">   </span><span class="mi">1881</span>     <span class="n">f</span><span class="p">,</span>
<span class="g g-Whitespace">   </span><span class="mi">1882</span>     <span class="n">mode</span><span class="p">,</span>
<span class="g g-Whitespace">   </span><span class="mi">1883</span>     <span class="n">encoding</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">options</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;encoding&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">),</span>
<span class="g g-Whitespace">   </span><span class="mi">1884</span>     <span class="n">compression</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">options</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;compression&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">),</span>
<span class="g g-Whitespace">   </span><span class="mi">1885</span>     <span class="n">memory_map</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">options</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;memory_map&quot;</span><span class="p">,</span> <span class="kc">False</span><span class="p">),</span>
<span class="g g-Whitespace">   </span><span class="mi">1886</span>     <span class="n">is_text</span><span class="o">=</span><span class="n">is_text</span><span class="p">,</span>
<span class="g g-Whitespace">   </span><span class="mi">1887</span>     <span class="n">errors</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">options</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;encoding_errors&quot;</span><span class="p">,</span> <span class="s2">&quot;strict&quot;</span><span class="p">),</span>
<span class="g g-Whitespace">   </span><span class="mi">1888</span>     <span class="n">storage_options</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">options</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;storage_options&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">),</span>
<span class="g g-Whitespace">   </span><span class="mi">1889</span> <span class="p">)</span>
<span class="g g-Whitespace">   </span><span class="mi">1890</span> <span class="k">assert</span> <span class="bp">self</span><span class="o">.</span><span class="n">handles</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>
<span class="g g-Whitespace">   </span><span class="mi">1891</span> <span class="n">f</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">handles</span><span class="o">.</span><span class="n">handle</span>

<span class="nn">File ~\AppData\Local\Programs\Python\Python312\Lib\site-packages\pandas\io\common.py:873,</span> in <span class="ni">get_handle</span><span class="nt">(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)</span>
<span class="g g-Whitespace">    </span><span class="mi">868</span> <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">handle</span><span class="p">,</span> <span class="nb">str</span><span class="p">):</span>
<span class="g g-Whitespace">    </span><span class="mi">869</span>     <span class="c1"># Check whether the filename is to be opened in binary mode.</span>
<span class="g g-Whitespace">    </span><span class="mi">870</span>     <span class="c1"># Binary mode does not support &#39;encoding&#39; and &#39;newline&#39;.</span>
<span class="g g-Whitespace">    </span><span class="mi">871</span>     <span class="k">if</span> <span class="n">ioargs</span><span class="o">.</span><span class="n">encoding</span> <span class="ow">and</span> <span class="s2">&quot;b&quot;</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">ioargs</span><span class="o">.</span><span class="n">mode</span><span class="p">:</span>
<span class="g g-Whitespace">    </span><span class="mi">872</span>         <span class="c1"># Encoding</span>
<span class="ne">--&gt; </span><span class="mi">873</span>         <span class="n">handle</span> <span class="o">=</span> <span class="nb">open</span><span class="p">(</span>
<span class="g g-Whitespace">    </span><span class="mi">874</span>             <span class="n">handle</span><span class="p">,</span>
<span class="g g-Whitespace">    </span><span class="mi">875</span>             <span class="n">ioargs</span><span class="o">.</span><span class="n">mode</span><span class="p">,</span>
<span class="g g-Whitespace">    </span><span class="mi">876</span>             <span class="n">encoding</span><span class="o">=</span><span class="n">ioargs</span><span class="o">.</span><span class="n">encoding</span><span class="p">,</span>
<span class="g g-Whitespace">    </span><span class="mi">877</span>             <span class="n">errors</span><span class="o">=</span><span class="n">errors</span><span class="p">,</span>
<span class="g g-Whitespace">    </span><span class="mi">878</span>             <span class="n">newline</span><span class="o">=</span><span class="s2">&quot;&quot;</span><span class="p">,</span>
<span class="g g-Whitespace">    </span><span class="mi">879</span>         <span class="p">)</span>
<span class="g g-Whitespace">    </span><span class="mi">880</span>     <span class="k">else</span><span class="p">:</span>
<span class="g g-Whitespace">    </span><span class="mi">881</span>         <span class="c1"># Binary mode</span>
<span class="g g-Whitespace">    </span><span class="mi">882</span>         <span class="n">handle</span> <span class="o">=</span> <span class="nb">open</span><span class="p">(</span><span class="n">handle</span><span class="p">,</span> <span class="n">ioargs</span><span class="o">.</span><span class="n">mode</span><span class="p">)</span>

<span class="ne">FileNotFoundError</span>: [Errno 2] No such file or directory: &#39;iris-full.csv&#39;
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">from</span> <span class="nn">sklearn.cluster</span> <span class="kn">import</span> <span class="n">KMeans</span>
<span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">MinMaxScaler</span>

<span class="c1"># Load data dari CSV</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s2">&quot;iris-full.csv&quot;</span><span class="p">)</span>  <span class="c1"># Ganti dengan nama file kamu</span>

<span class="c1"># Simpan kolom ID dan Class</span>
<span class="n">df_id_class</span> <span class="o">=</span> <span class="n">df</span><span class="p">[[</span><span class="s1">&#39;id&#39;</span><span class="p">,</span> <span class="s1">&#39;Class&#39;</span><span class="p">]]</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>

<span class="c1"># Ambil fitur numerik</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">df</span><span class="p">[[</span><span class="s1">&#39;petal length&#39;</span><span class="p">,</span> <span class="s1">&#39;petal width&#39;</span><span class="p">]]</span>

<span class="c1"># Normalisasi dengan MinMaxScaler</span>
<span class="n">scaler</span> <span class="o">=</span> <span class="n">MinMaxScaler</span><span class="p">()</span>
<span class="n">X_scaled</span> <span class="o">=</span> <span class="n">scaler</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>

<span class="c1"># KMeans Clustering</span>
<span class="n">kmeans</span> <span class="o">=</span> <span class="n">KMeans</span><span class="p">(</span><span class="n">n_clusters</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>
<span class="n">kmeans</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_scaled</span><span class="p">)</span>

<span class="c1"># Tambahkan hasil klaster ke dataframe</span>
<span class="n">df_id_class</span><span class="p">[</span><span class="s1">&#39;Cluster&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">kmeans</span><span class="o">.</span><span class="n">labels_</span>

<span class="c1"># Mapping klaster ke label kelas berdasarkan majority vote</span>
<span class="n">cluster_to_class</span> <span class="o">=</span> <span class="p">{}</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">3</span><span class="p">):</span>
    <span class="n">mode_class</span> <span class="o">=</span> <span class="n">df_id_class</span><span class="p">[</span><span class="n">df_id_class</span><span class="p">[</span><span class="s1">&#39;Cluster&#39;</span><span class="p">]</span> <span class="o">==</span> <span class="n">i</span><span class="p">][</span><span class="s1">&#39;Class&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">mode</span><span class="p">()</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">mode_class</span><span class="o">.</span><span class="n">empty</span><span class="p">:</span>
        <span class="n">cluster_to_class</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">mode_class</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>

<span class="c1"># Buat kolom prediksi berdasarkan cluster</span>
<span class="n">df_id_class</span><span class="p">[</span><span class="s1">&#39;PredictedClass&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">df_id_class</span><span class="p">[</span><span class="s1">&#39;Cluster&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">cluster_to_class</span><span class="p">)</span>

<span class="c1"># Tandai data yang salah klasifikasi</span>
<span class="n">df_id_class</span><span class="p">[</span><span class="s1">&#39;Misclassified&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">df_id_class</span><span class="p">[</span><span class="s1">&#39;Class&#39;</span><span class="p">]</span> <span class="o">!=</span> <span class="n">df_id_class</span><span class="p">[</span><span class="s1">&#39;PredictedClass&#39;</span><span class="p">]</span>

<span class="c1"># -------------------------------</span>
<span class="c1"># Tampilkan semua data (ID 1‚Äì150)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;=== Seluruh hasil clustering K-Means ===&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">df_id_class</span><span class="o">.</span><span class="n">sort_values</span><span class="p">(</span><span class="n">by</span><span class="o">=</span><span class="s1">&#39;id&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">to_string</span><span class="p">(</span><span class="n">index</span><span class="o">=</span><span class="kc">False</span><span class="p">))</span>

<span class="c1"># -------------------------------</span>
<span class="c1"># Tampilkan data yang salah klasifikasi</span>
<span class="n">salah</span> <span class="o">=</span> <span class="n">df_id_class</span><span class="p">[</span><span class="n">df_id_class</span><span class="p">[</span><span class="s1">&#39;Misclassified&#39;</span><span class="p">]]</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">=== Data yang salah klasifikasi ===&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">salah</span><span class="p">[[</span><span class="s1">&#39;id&#39;</span><span class="p">,</span> <span class="s1">&#39;Class&#39;</span><span class="p">,</span> <span class="s1">&#39;Cluster&#39;</span><span class="p">,</span> <span class="s1">&#39;PredictedClass&#39;</span><span class="p">]]</span><span class="o">.</span><span class="n">to_string</span><span class="p">(</span><span class="n">index</span><span class="o">=</span><span class="kc">False</span><span class="p">))</span>

<span class="c1"># -------------------------------</span>
<span class="c1"># Tambahan: jumlah salah</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Total salah klasifikasi: </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">salah</span><span class="p">)</span><span class="si">}</span><span class="s2"> dari </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">df_id_class</span><span class="p">)</span><span class="si">}</span><span class="s2"> data&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>=== Seluruh hasil clustering K-Means ===
 id           Class  Cluster  PredictedClass  Misclassified
  1     Iris-setosa        1     Iris-setosa          False
  2     Iris-setosa        1     Iris-setosa          False
  3     Iris-setosa        1     Iris-setosa          False
  4     Iris-setosa        1     Iris-setosa          False
  5     Iris-setosa        1     Iris-setosa          False
  6     Iris-setosa        1     Iris-setosa          False
  7     Iris-setosa        1     Iris-setosa          False
  8     Iris-setosa        1     Iris-setosa          False
  9     Iris-setosa        1     Iris-setosa          False
 10     Iris-setosa        1     Iris-setosa          False
 11     Iris-setosa        1     Iris-setosa          False
 12     Iris-setosa        1     Iris-setosa          False
 13     Iris-setosa        1     Iris-setosa          False
 14     Iris-setosa        1     Iris-setosa          False
 15     Iris-setosa        1     Iris-setosa          False
 16     Iris-setosa        1     Iris-setosa          False
 17     Iris-setosa        1     Iris-setosa          False
 18     Iris-setosa        1     Iris-setosa          False
 19     Iris-setosa        1     Iris-setosa          False
 20     Iris-setosa        1     Iris-setosa          False
 21     Iris-setosa        1     Iris-setosa          False
 22     Iris-setosa        1     Iris-setosa          False
 23     Iris-setosa        1     Iris-setosa          False
 24     Iris-setosa        1     Iris-setosa          False
 25     Iris-setosa        1     Iris-setosa          False
 26     Iris-setosa        1     Iris-setosa          False
 27     Iris-setosa        1     Iris-setosa          False
 28     Iris-setosa        1     Iris-setosa          False
 29     Iris-setosa        1     Iris-setosa          False
 30     Iris-setosa        1     Iris-setosa          False
 31     Iris-setosa        1     Iris-setosa          False
 32     Iris-setosa        1     Iris-setosa          False
 33     Iris-setosa        1     Iris-setosa          False
 34     Iris-setosa        1     Iris-setosa          False
 35     Iris-setosa        1     Iris-setosa          False
 36     Iris-setosa        1     Iris-setosa          False
 37     Iris-setosa        1     Iris-setosa          False
 38     Iris-setosa        1     Iris-setosa          False
 39     Iris-setosa        1     Iris-setosa          False
 40     Iris-setosa        1     Iris-setosa          False
 41     Iris-setosa        1     Iris-setosa          False
 42     Iris-setosa        1     Iris-setosa          False
 43     Iris-setosa        1     Iris-setosa          False
 44     Iris-setosa        1     Iris-setosa          False
 45     Iris-setosa        1     Iris-setosa          False
 46     Iris-setosa        1     Iris-setosa          False
 47     Iris-setosa        1     Iris-setosa          False
 48     Iris-setosa        1     Iris-setosa          False
 49     Iris-setosa        1     Iris-setosa          False
 50     Iris-setosa        1     Iris-setosa          False
 51 Iris-versicolor        2 Iris-versicolor          False
 52 Iris-versicolor        2 Iris-versicolor          False
 53 Iris-versicolor        2 Iris-versicolor          False
 54 Iris-versicolor        2 Iris-versicolor          False
 55 Iris-versicolor        2 Iris-versicolor          False
 56 Iris-versicolor        2 Iris-versicolor          False
 57 Iris-versicolor        2 Iris-versicolor          False
 58 Iris-versicolor        2 Iris-versicolor          False
 59 Iris-versicolor        2 Iris-versicolor          False
 60 Iris-versicolor        2 Iris-versicolor          False
 61 Iris-versicolor        2 Iris-versicolor          False
 62 Iris-versicolor        2 Iris-versicolor          False
 63 Iris-versicolor        2 Iris-versicolor          False
 64 Iris-versicolor        2 Iris-versicolor          False
 65 Iris-versicolor        2 Iris-versicolor          False
 66 Iris-versicolor        2 Iris-versicolor          False
 67 Iris-versicolor        2 Iris-versicolor          False
 68 Iris-versicolor        2 Iris-versicolor          False
 69 Iris-versicolor        2 Iris-versicolor          False
 70 Iris-versicolor        2 Iris-versicolor          False
 71 Iris-versicolor        0  Iris-virginica           True
 72 Iris-versicolor        2 Iris-versicolor          False
 73 Iris-versicolor        2 Iris-versicolor          False
 74 Iris-versicolor        2 Iris-versicolor          False
 75 Iris-versicolor        2 Iris-versicolor          False
 76 Iris-versicolor        2 Iris-versicolor          False
 77 Iris-versicolor        2 Iris-versicolor          False
 78 Iris-versicolor        0  Iris-virginica           True
 79 Iris-versicolor        2 Iris-versicolor          False
 80 Iris-versicolor        2 Iris-versicolor          False
 81 Iris-versicolor        2 Iris-versicolor          False
 82 Iris-versicolor        2 Iris-versicolor          False
 83 Iris-versicolor        2 Iris-versicolor          False
 84 Iris-versicolor        2 Iris-versicolor          False
 85 Iris-versicolor        2 Iris-versicolor          False
 86 Iris-versicolor        2 Iris-versicolor          False
 87 Iris-versicolor        2 Iris-versicolor          False
 88 Iris-versicolor        2 Iris-versicolor          False
 89 Iris-versicolor        2 Iris-versicolor          False
 90 Iris-versicolor        2 Iris-versicolor          False
 91 Iris-versicolor        2 Iris-versicolor          False
 92 Iris-versicolor        2 Iris-versicolor          False
 93 Iris-versicolor        2 Iris-versicolor          False
 94 Iris-versicolor        2 Iris-versicolor          False
 95 Iris-versicolor        2 Iris-versicolor          False
 96 Iris-versicolor        2 Iris-versicolor          False
 97 Iris-versicolor        2 Iris-versicolor          False
 98 Iris-versicolor        2 Iris-versicolor          False
 99 Iris-versicolor        2 Iris-versicolor          False
100 Iris-versicolor        2 Iris-versicolor          False
101  Iris-virginica        0  Iris-virginica          False
102  Iris-virginica        0  Iris-virginica          False
103  Iris-virginica        0  Iris-virginica          False
104  Iris-virginica        0  Iris-virginica          False
105  Iris-virginica        0  Iris-virginica          False
106  Iris-virginica        0  Iris-virginica          False
107  Iris-virginica        2 Iris-versicolor           True
108  Iris-virginica        0  Iris-virginica          False
109  Iris-virginica        0  Iris-virginica          False
110  Iris-virginica        0  Iris-virginica          False
111  Iris-virginica        0  Iris-virginica          False
112  Iris-virginica        0  Iris-virginica          False
113  Iris-virginica        0  Iris-virginica          False
114  Iris-virginica        0  Iris-virginica          False
115  Iris-virginica        0  Iris-virginica          False
116  Iris-virginica        0  Iris-virginica          False
117  Iris-virginica        0  Iris-virginica          False
118  Iris-virginica        0  Iris-virginica          False
119  Iris-virginica        0  Iris-virginica          False
120  Iris-virginica        2 Iris-versicolor           True
121  Iris-virginica        0  Iris-virginica          False
122  Iris-virginica        0  Iris-virginica          False
123  Iris-virginica        0  Iris-virginica          False
124  Iris-virginica        0  Iris-virginica          False
125  Iris-virginica        0  Iris-virginica          False
126  Iris-virginica        0  Iris-virginica          False
127  Iris-virginica        0  Iris-virginica          False
128  Iris-virginica        0  Iris-virginica          False
129  Iris-virginica        0  Iris-virginica          False
130  Iris-virginica        0  Iris-virginica          False
131  Iris-virginica        0  Iris-virginica          False
132  Iris-virginica        0  Iris-virginica          False
133  Iris-virginica        0  Iris-virginica          False
134  Iris-virginica        2 Iris-versicolor           True
135  Iris-virginica        2 Iris-versicolor           True
136  Iris-virginica        0  Iris-virginica          False
137  Iris-virginica        0  Iris-virginica          False
138  Iris-virginica        0  Iris-virginica          False
139  Iris-virginica        0  Iris-virginica          False
140  Iris-virginica        0  Iris-virginica          False
141  Iris-virginica        0  Iris-virginica          False
142  Iris-virginica        0  Iris-virginica          False
143  Iris-virginica        0  Iris-virginica          False
144  Iris-virginica        0  Iris-virginica          False
145  Iris-virginica        0  Iris-virginica          False
146  Iris-virginica        0  Iris-virginica          False
147  Iris-virginica        0  Iris-virginica          False
148  Iris-virginica        0  Iris-virginica          False
149  Iris-virginica        0  Iris-virginica          False
150  Iris-virginica        0  Iris-virginica          False

=== Data yang salah klasifikasi ===
 id           Class  Cluster  PredictedClass
 71 Iris-versicolor        0  Iris-virginica
 78 Iris-versicolor        0  Iris-virginica
107  Iris-virginica        2 Iris-versicolor
120  Iris-virginica        2 Iris-versicolor
134  Iris-virginica        2 Iris-versicolor
135  Iris-virginica        2 Iris-versicolor

Total salah klasifikasi: 6 dari 150 data
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Drop kolom class</span>
<span class="n">df_no_label</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;Class&#39;</span><span class="p">])</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="clustering-untuk-class-sepal-lenght">
<h2>clustering untuk class sepal lenght<a class="headerlink" href="#clustering-untuk-class-sepal-lenght" title="Link to this heading">#</a></h2>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">from</span> <span class="nn">sklearn.cluster</span> <span class="kn">import</span> <span class="n">KMeans</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>

<span class="c1"># 1. Load data</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">&#39;iris-full.csv&#39;</span><span class="p">)</span>

<span class="c1"># 2. Ekstrak hanya kolom &#39;sepal length&#39; sebagai array 2D</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">df</span><span class="p">[[</span><span class="s1">&#39;sepal length&#39;</span><span class="p">]]</span><span class="o">.</span><span class="n">values</span>

<span class="c1"># 3. Menentukan jumlah cluster = 4</span>
<span class="n">n_clusters</span> <span class="o">=</span> <span class="mi">4</span>

<span class="c1"># 4. Membuat model K-Means</span>
<span class="n">kmeans</span> <span class="o">=</span> <span class="n">KMeans</span><span class="p">(</span><span class="n">n_clusters</span><span class="o">=</span><span class="n">n_clusters</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">,</span> <span class="n">n_init</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
<span class="n">kmeans</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>

<span class="c1"># 5. Mendapatkan label cluster dan konversi ke huruf (A, B, C, D)</span>
<span class="n">numeric_labels</span> <span class="o">=</span> <span class="n">kmeans</span><span class="o">.</span><span class="n">labels_</span>
<span class="n">letter_labels</span> <span class="o">=</span> <span class="p">[</span><span class="nb">chr</span><span class="p">(</span><span class="mi">65</span> <span class="o">+</span> <span class="n">label</span><span class="p">)</span> <span class="k">for</span> <span class="n">label</span> <span class="ow">in</span> <span class="n">numeric_labels</span><span class="p">]</span>  <span class="c1"># 65 = &#39;A&#39; dalam ASCII</span>

<span class="c1"># 6. Menambahkan hasil clustering ke dataframe</span>
<span class="n">df</span><span class="p">[</span><span class="s1">&#39;Cluster&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">letter_labels</span>

<span class="c1"># 7. Visualisasi hasil clustering</span>
<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">12</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>

<span class="c1"># Warna untuk setiap cluster</span>
<span class="n">colors</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;red&#39;</span><span class="p">,</span> <span class="s1">&#39;blue&#39;</span><span class="p">,</span> <span class="s1">&#39;green&#39;</span><span class="p">,</span> <span class="s1">&#39;purple&#39;</span><span class="p">]</span>

<span class="c1"># Plot data points untuk setiap cluster</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_clusters</span><span class="p">):</span>
    <span class="n">cluster_data</span> <span class="o">=</span> <span class="n">X</span><span class="p">[</span><span class="n">numeric_labels</span> <span class="o">==</span> <span class="n">i</span><span class="p">]</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">cluster_data</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="n">cluster_data</span><span class="p">),</span>
                <span class="n">color</span><span class="o">=</span><span class="n">colors</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">label</span><span class="o">=</span><span class="sa">f</span><span class="s1">&#39;Cluster </span><span class="si">{</span><span class="nb">chr</span><span class="p">(</span><span class="mi">65</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">i</span><span class="p">)</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.7</span><span class="p">)</span>

<span class="c1"># Plot centroids</span>
<span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">kmeans</span><span class="o">.</span><span class="n">cluster_centers_</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">n_clusters</span><span class="p">),</span>
            <span class="n">marker</span><span class="o">=</span><span class="s1">&#39;X&#39;</span><span class="p">,</span> <span class="n">s</span><span class="o">=</span><span class="mi">200</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="s1">&#39;black&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Centroids&#39;</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;K-Means Clustering pada Sepal Length (4 Cluster)&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Sepal Length (cm)&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">yticks</span><span class="p">([])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="kc">True</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>

<span class="c1"># 8. Menampilkan statistik deskriptif per cluster</span>
<span class="n">cluster_stats</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">groupby</span><span class="p">(</span><span class="s1">&#39;Cluster&#39;</span><span class="p">)[</span><span class="s1">&#39;sepal length&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">describe</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Statistik Deskriptif per Cluster:&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">cluster_stats</span><span class="p">)</span>

<span class="c1"># 9. Menampilkan 10 data pertama dengan label cluster</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Contoh Data dengan Label Cluster:&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">df</span><span class="p">[[</span><span class="s1">&#39;sepal length&#39;</span><span class="p">,</span> <span class="s1">&#39;Cluster&#39;</span><span class="p">]]</span><span class="o">.</span><span class="n">head</span><span class="p">(</span><span class="mi">10</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/a48a6389a4bcef07d57a8b5fcfe6cecc84c73e835abe37ac7b1005592afb0179.png" src="_images/a48a6389a4bcef07d57a8b5fcfe6cecc84c73e835abe37ac7b1005592afb0179.png" />
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Statistik Deskriptif per Cluster:
         count      mean       std  min  25%  50%  75%  max
Cluster                                                    
A         49.0  5.734694  0.228720  5.4  5.5  5.7  5.9  6.1
B         12.0  7.475000  0.270101  7.1  7.2  7.5  7.7  7.9
C         46.0  4.895652  0.246718  4.3  4.8  5.0  5.1  5.3
D         43.0  6.525581  0.232064  6.2  6.3  6.5  6.7  7.0

Contoh Data dengan Label Cluster:
   sepal length Cluster
0           5.1       C
1           4.9       C
2           4.7       C
3           4.6       C
4           5.0       C
5           5.4       A
6           4.6       C
7           5.0       C
8           4.4       C
9           4.9       C
</pre></div>
</div>
</div>
</div>
</section>
<section id="menggabungkan-data-hasil-cluster-dengan-data-original">
<h2>menggabungkan data hasil cluster dengan data original<a class="headerlink" href="#menggabungkan-data-hasil-cluster-dengan-data-original" title="Link to this heading">#</a></h2>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">from</span> <span class="nn">sklearn.cluster</span> <span class="kn">import</span> <span class="n">KMeans</span>

<span class="c1"># 1. Load data</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">&#39;iris-full.csv&#39;</span><span class="p">)</span>

<span class="c1"># 2. Ekstrak kolom &#39;sepal length&#39;</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">df</span><span class="p">[[</span><span class="s1">&#39;sepal length&#39;</span><span class="p">]]</span><span class="o">.</span><span class="n">values</span>

<span class="c1"># 3. Clustering dengan 4 cluster</span>
<span class="n">kmeans</span> <span class="o">=</span> <span class="n">KMeans</span><span class="p">(</span><span class="n">n_clusters</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">,</span> <span class="n">n_init</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
<span class="n">kmeans</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
<span class="n">df</span><span class="p">[</span><span class="s1">&#39;Cluster&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="p">[</span><span class="nb">chr</span><span class="p">(</span><span class="mi">65</span> <span class="o">+</span> <span class="n">label</span><span class="p">)</span> <span class="k">for</span> <span class="n">label</span> <span class="ow">in</span> <span class="n">kmeans</span><span class="o">.</span><span class="n">labels_</span><span class="p">]</span>  <span class="c1"># Konversi ke A,B,C,D</span>

<span class="c1"># 4. GANTI kolom &#39;sepal length&#39; asli dengan label cluster</span>
<span class="n">df</span><span class="p">[</span><span class="s1">&#39;sepal length&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;Cluster&#39;</span><span class="p">]</span>  <span class="c1"># Overwrite nilai numerik dengan kategori</span>

<span class="c1"># 5. Hapus kolom Cluster tambahan (opsional)</span>
<span class="n">df</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="s1">&#39;Cluster&#39;</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="c1"># 6. Simpan hasil (opsional)</span>
<span class="n">df</span><span class="o">.</span><span class="n">to_csv</span><span class="p">(</span><span class="s1">&#39;iris_sepal_length_categorical.csv&#39;</span><span class="p">,</span> <span class="n">index</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

<span class="c1"># 7. Tampilkan hasil</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Data setelah transformasi:&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">df</span><span class="o">.</span><span class="n">head</span><span class="p">(</span><span class="mi">10</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Data setelah transformasi:
   id        Class sepal length  sepal width  petal length  petal width
0   1  Iris-setosa            C          3.5           1.4          0.2
1   2  Iris-setosa            C          3.0           1.4          0.2
2   3  Iris-setosa            C          3.2           1.3          0.2
3   4  Iris-setosa            C          3.1           1.5          0.2
4   5  Iris-setosa            C          3.6           1.4          0.2
5   6  Iris-setosa            A          3.9           1.7          0.4
6   7  Iris-setosa            C          3.4           1.4          0.3
7   8  Iris-setosa            C          3.4           1.5          0.2
8   9  Iris-setosa            C          2.9           1.4          0.2
9  10  Iris-setosa            C          3.1           1.5          0.1
</pre></div>
</div>
</div>
</div>
</section>
<section id="clustering-untuk-clas-sisa">
<h2>clustering untuk clas sisa<a class="headerlink" href="#clustering-untuk-clas-sisa" title="Link to this heading">#</a></h2>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">from</span> <span class="nn">sklearn.cluster</span> <span class="kn">import</span> <span class="n">KMeans</span>

<span class="c1"># 1. Load data</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">&#39;iris-full.csv&#39;</span><span class="p">)</span>

<span class="c1"># 2. Daftar kolom yang akan di-cluster</span>
<span class="n">features</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;sepal length&#39;</span><span class="p">,</span> <span class="s1">&#39;sepal width&#39;</span><span class="p">,</span> <span class="s1">&#39;petal length&#39;</span><span class="p">,</span> <span class="s1">&#39;petal width&#39;</span><span class="p">]</span>
<span class="n">n_clusters</span> <span class="o">=</span> <span class="mi">4</span>  <span class="c1"># Jumlah cluster untuk setiap fitur</span>

<span class="c1"># 3. Lakukan clustering untuk setiap fitur</span>
<span class="k">for</span> <span class="n">feature</span> <span class="ow">in</span> <span class="n">features</span><span class="p">:</span>
    <span class="c1"># Ekstrak data</span>
    <span class="n">X</span> <span class="o">=</span> <span class="n">df</span><span class="p">[[</span><span class="n">feature</span><span class="p">]]</span><span class="o">.</span><span class="n">values</span>

    <span class="c1"># Clustering</span>
    <span class="n">kmeans</span> <span class="o">=</span> <span class="n">KMeans</span><span class="p">(</span><span class="n">n_clusters</span><span class="o">=</span><span class="n">n_clusters</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">,</span> <span class="n">n_init</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
    <span class="n">kmeans</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>

    <span class="c1"># Konversi label ke huruf (A, B, C, D)</span>
    <span class="n">cluster_labels</span> <span class="o">=</span> <span class="p">[</span><span class="nb">chr</span><span class="p">(</span><span class="mi">65</span> <span class="o">+</span> <span class="n">label</span><span class="p">)</span> <span class="k">for</span> <span class="n">label</span> <span class="ow">in</span> <span class="n">kmeans</span><span class="o">.</span><span class="n">labels_</span><span class="p">]</span>

    <span class="c1"># Ganti kolom numerik dengan kategori cluster</span>
    <span class="n">df</span><span class="p">[</span><span class="n">feature</span><span class="p">]</span> <span class="o">=</span> <span class="n">cluster_labels</span>

<span class="c1"># 4. Simpan hasil (opsional)</span>
<span class="n">df</span><span class="o">.</span><span class="n">to_csv</span><span class="p">(</span><span class="s1">&#39;iris_all_features_clustered.csv&#39;</span><span class="p">,</span> <span class="n">index</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

<span class="c1"># 5. Tampilkan hasil</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Data setelah transformasi:&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">df</span><span class="o">.</span><span class="n">head</span><span class="p">(</span><span class="mi">20</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Distribusi nilai per fitur:&quot;</span><span class="p">)</span>
<span class="k">for</span> <span class="n">feature</span> <span class="ow">in</span> <span class="n">features</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="se">\n</span><span class="si">{</span><span class="n">feature</span><span class="si">}</span><span class="s2">:&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="n">feature</span><span class="p">]</span><span class="o">.</span><span class="n">value_counts</span><span class="p">())</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Data setelah transformasi:
    id        Class sepal length sepal width petal length petal width
0    1  Iris-setosa            C           D            B           A
1    2  Iris-setosa            C           A            B           A
2    3  Iris-setosa            C           D            B           A
3    4  Iris-setosa            C           A            B           A
4    5  Iris-setosa            C           B            B           A
5    6  Iris-setosa            A           B            B           A
6    7  Iris-setosa            C           D            B           A
7    8  Iris-setosa            C           D            B           A
8    9  Iris-setosa            C           A            B           A
9   10  Iris-setosa            C           A            B           A
10  11  Iris-setosa            A           B            B           A
11  12  Iris-setosa            C           D            B           A
12  13  Iris-setosa            C           A            B           A
13  14  Iris-setosa            C           A            B           A
14  15  Iris-setosa            A           B            B           A
15  16  Iris-setosa            A           B            B           A
16  17  Iris-setosa            A           B            B           A
17  18  Iris-setosa            C           D            B           A
18  19  Iris-setosa            A           B            B           A
19  20  Iris-setosa            C           B            B           A

Distribusi nilai per fitur:

sepal length:
sepal length
A    49
C    46
D    43
B    12
Name: count, dtype: int64

sepal width:
sepal width
A    71
D    37
C    24
B    18
Name: count, dtype: int64

petal length:
petal length
B    50
A    45
D    30
C    25
Name: count, dtype: int64

petal width:
petal width
A    50
B    48
C    29
D    23
Name: count, dtype: int64
</pre></div>
</div>
</div>
</div>
</section>
<section id="klasifikasi-data-yang-sudah-di-diskritisasi-dengan-menggunakan-metode-naive-baiyes-dan-decision-tree">
<h2>klasifikasi data yang sudah di diskritisasi dengan menggunakan metode naive baiyes dan decision tree<a class="headerlink" href="#klasifikasi-data-yang-sudah-di-diskritisasi-dengan-menggunakan-metode-naive-baiyes-dan-decision-tree" title="Link to this heading">#</a></h2>
<section id="klasifikasi-dengan-naive-baiyes">
<h3>klasifikasi dengan naive baiyes<a class="headerlink" href="#klasifikasi-dengan-naive-baiyes" title="Link to this heading">#</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span>
<span class="kn">from</span> <span class="nn">sklearn.naive_bayes</span> <span class="kn">import</span> <span class="n">CategoricalNB</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">classification_report</span><span class="p">,</span> <span class="n">accuracy_score</span>
<span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">LabelEncoder</span>

<span class="c1"># 1. Load data yang sudah didiskritisasi</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">&#39;iris_all_features_clustered.csv&#39;</span><span class="p">)</span>

<span class="c1"># 2. Encode label kelas dan fitur kategorikal</span>
<span class="n">le_class</span> <span class="o">=</span> <span class="n">LabelEncoder</span><span class="p">()</span>
<span class="n">df</span><span class="p">[</span><span class="s1">&#39;Class&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">le_class</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;Class&#39;</span><span class="p">])</span>

<span class="c1"># Encode setiap fitur kategorikal</span>
<span class="n">feature_encoders</span> <span class="o">=</span> <span class="p">{}</span>
<span class="k">for</span> <span class="n">feature</span> <span class="ow">in</span> <span class="p">[</span><span class="s1">&#39;sepal length&#39;</span><span class="p">,</span> <span class="s1">&#39;sepal width&#39;</span><span class="p">,</span> <span class="s1">&#39;petal length&#39;</span><span class="p">,</span> <span class="s1">&#39;petal width&#39;</span><span class="p">]:</span>
    <span class="n">le</span> <span class="o">=</span> <span class="n">LabelEncoder</span><span class="p">()</span>
    <span class="n">df</span><span class="p">[</span><span class="n">feature</span><span class="p">]</span> <span class="o">=</span> <span class="n">le</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="n">feature</span><span class="p">])</span>
    <span class="n">feature_encoders</span><span class="p">[</span><span class="n">feature</span><span class="p">]</span> <span class="o">=</span> <span class="n">le</span>  <span class="c1"># Simpan encoder untuk referensi</span>

<span class="c1"># 3. Pisahkan fitur dan target</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">df</span><span class="p">[[</span><span class="s1">&#39;sepal length&#39;</span><span class="p">,</span> <span class="s1">&#39;sepal width&#39;</span><span class="p">,</span> <span class="s1">&#39;petal length&#39;</span><span class="p">,</span> <span class="s1">&#39;petal width&#39;</span><span class="p">]]</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;Class&#39;</span><span class="p">]</span>

<span class="c1"># 4. Bagi data menjadi training dan testing set</span>
<span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.3</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>

<span class="c1"># 5. Buat dan latih model Naive Bayes</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">CategoricalNB</span><span class="p">()</span>
<span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>

<span class="c1"># 6. Prediksi pada data test</span>
<span class="n">y_pred</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>

<span class="c1"># 7. Evaluasi model</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Accuracy:&quot;</span><span class="p">,</span> <span class="n">accuracy_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Classification Report:&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">classification_report</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">,</span> <span class="n">target_names</span><span class="o">=</span><span class="n">le_class</span><span class="o">.</span><span class="n">classes_</span><span class="p">))</span>

<span class="c1"># 8. Contoh prediksi dengan decoding</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Contoh prediksi pada 5 data test:&quot;</span><span class="p">)</span>
<span class="n">sample</span> <span class="o">=</span> <span class="n">X_test</span><span class="o">.</span><span class="n">head</span><span class="p">()</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
<span class="k">for</span> <span class="n">feature</span> <span class="ow">in</span> <span class="n">sample</span><span class="o">.</span><span class="n">columns</span><span class="p">:</span>
    <span class="n">sample</span><span class="p">[</span><span class="n">feature</span><span class="p">]</span> <span class="o">=</span> <span class="n">feature_encoders</span><span class="p">[</span><span class="n">feature</span><span class="p">]</span><span class="o">.</span><span class="n">inverse_transform</span><span class="p">(</span><span class="n">sample</span><span class="p">[</span><span class="n">feature</span><span class="p">])</span>

<span class="n">sample</span><span class="p">[</span><span class="s1">&#39;True Class&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">le_class</span><span class="o">.</span><span class="n">inverse_transform</span><span class="p">(</span><span class="n">y_test</span><span class="o">.</span><span class="n">head</span><span class="p">())</span>
<span class="n">sample</span><span class="p">[</span><span class="s1">&#39;Predicted Class&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">le_class</span><span class="o">.</span><span class="n">inverse_transform</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="o">.</span><span class="n">head</span><span class="p">()))</span>
<span class="nb">print</span><span class="p">(</span><span class="n">sample</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Accuracy: 0.9555555555555556

Classification Report:
                 precision    recall  f1-score   support

    Iris-setosa       1.00      1.00      1.00        19
Iris-versicolor       1.00      0.85      0.92        13
 Iris-virginica       0.87      1.00      0.93        13

       accuracy                           0.96        45
      macro avg       0.96      0.95      0.95        45
   weighted avg       0.96      0.96      0.96        45


Contoh prediksi pada 5 data test:
    sepal length sepal width petal length petal width       True Class  \
73             A           A            A           B  Iris-versicolor   
18             A           B            B           A      Iris-setosa   
118            B           C            D           D   Iris-virginica   
78             A           A            A           B  Iris-versicolor   
76             D           A            A           B  Iris-versicolor   

     Predicted Class  
73   Iris-versicolor  
18       Iris-setosa  
118   Iris-virginica  
78   Iris-versicolor  
76   Iris-versicolor  
</pre></div>
</div>
</div>
</div>
</section>
<section id="klasifikasi-dengan-decision-tree">
<h3>klasifikasi dengan decision tree<a class="headerlink" href="#klasifikasi-dengan-decision-tree" title="Link to this heading">#</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span>
<span class="kn">from</span> <span class="nn">sklearn.tree</span> <span class="kn">import</span> <span class="n">DecisionTreeClassifier</span><span class="p">,</span> <span class="n">plot_tree</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">classification_report</span><span class="p">,</span> <span class="n">accuracy_score</span>
<span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">LabelEncoder</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>

<span class="c1"># 1. Load data yang sudah didiskritisasi</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">&#39;iris_all_features_clustered.csv&#39;</span><span class="p">)</span>

<span class="c1"># 2. Encode label kelas dan fitur kategorikal</span>
<span class="n">le_class</span> <span class="o">=</span> <span class="n">LabelEncoder</span><span class="p">()</span>
<span class="n">df</span><span class="p">[</span><span class="s1">&#39;Class&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">le_class</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;Class&#39;</span><span class="p">])</span>

<span class="n">feature_encoders</span> <span class="o">=</span> <span class="p">{}</span>
<span class="k">for</span> <span class="n">feature</span> <span class="ow">in</span> <span class="p">[</span><span class="s1">&#39;sepal length&#39;</span><span class="p">,</span> <span class="s1">&#39;sepal width&#39;</span><span class="p">,</span> <span class="s1">&#39;petal length&#39;</span><span class="p">,</span> <span class="s1">&#39;petal width&#39;</span><span class="p">]:</span>
    <span class="n">le</span> <span class="o">=</span> <span class="n">LabelEncoder</span><span class="p">()</span>
    <span class="n">df</span><span class="p">[</span><span class="n">feature</span><span class="p">]</span> <span class="o">=</span> <span class="n">le</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="n">feature</span><span class="p">])</span>
    <span class="n">feature_encoders</span><span class="p">[</span><span class="n">feature</span><span class="p">]</span> <span class="o">=</span> <span class="n">le</span>

<span class="c1"># 3. Pisahkan fitur dan target</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">df</span><span class="p">[[</span><span class="s1">&#39;sepal length&#39;</span><span class="p">,</span> <span class="s1">&#39;sepal width&#39;</span><span class="p">,</span> <span class="s1">&#39;petal length&#39;</span><span class="p">,</span> <span class="s1">&#39;petal width&#39;</span><span class="p">]]</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;Class&#39;</span><span class="p">]</span>

<span class="c1"># 4. Bagi data menjadi training dan testing set</span>
<span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.3</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>

<span class="c1"># 5. Buat dan latih model Decision Tree</span>
<span class="n">dt_model</span> <span class="o">=</span> <span class="n">DecisionTreeClassifier</span><span class="p">(</span><span class="n">max_depth</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>
<span class="n">dt_model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>

<span class="c1"># 6. Prediksi pada data test</span>
<span class="n">y_pred</span> <span class="o">=</span> <span class="n">dt_model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>

<span class="c1"># 7. Evaluasi model</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Accuracy:&quot;</span><span class="p">,</span> <span class="n">accuracy_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Classification Report:&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">classification_report</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">,</span> <span class="n">target_names</span><span class="o">=</span><span class="n">le_class</span><span class="o">.</span><span class="n">classes_</span><span class="p">))</span>

<span class="c1"># 8. Visualisasi Decision Tree</span>
<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">20</span><span class="p">,</span><span class="mi">10</span><span class="p">))</span>
<span class="n">plot_tree</span><span class="p">(</span><span class="n">dt_model</span><span class="p">,</span>
          <span class="n">feature_names</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;sepal length&#39;</span><span class="p">,</span> <span class="s1">&#39;sepal width&#39;</span><span class="p">,</span> <span class="s1">&#39;petal length&#39;</span><span class="p">,</span> <span class="s1">&#39;petal width&#39;</span><span class="p">],</span>
          <span class="n">class_names</span><span class="o">=</span><span class="n">le_class</span><span class="o">.</span><span class="n">classes_</span><span class="p">,</span>
          <span class="n">filled</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
          <span class="n">rounded</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;Decision Tree untuk Data Iris yang Didiskritisasi&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>

<span class="c1"># 9. Contoh prediksi dengan decoding</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Contoh prediksi pada 5 data test:&quot;</span><span class="p">)</span>
<span class="n">sample</span> <span class="o">=</span> <span class="n">X_test</span><span class="o">.</span><span class="n">head</span><span class="p">()</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
<span class="k">for</span> <span class="n">feature</span> <span class="ow">in</span> <span class="n">sample</span><span class="o">.</span><span class="n">columns</span><span class="p">:</span>
    <span class="n">sample</span><span class="p">[</span><span class="n">feature</span><span class="p">]</span> <span class="o">=</span> <span class="n">feature_encoders</span><span class="p">[</span><span class="n">feature</span><span class="p">]</span><span class="o">.</span><span class="n">inverse_transform</span><span class="p">(</span><span class="n">sample</span><span class="p">[</span><span class="n">feature</span><span class="p">])</span>

<span class="n">sample</span><span class="p">[</span><span class="s1">&#39;True Class&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">le_class</span><span class="o">.</span><span class="n">inverse_transform</span><span class="p">(</span><span class="n">y_test</span><span class="o">.</span><span class="n">head</span><span class="p">())</span>
<span class="n">sample</span><span class="p">[</span><span class="s1">&#39;Predicted Class&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">le_class</span><span class="o">.</span><span class="n">inverse_transform</span><span class="p">(</span><span class="n">dt_model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="o">.</span><span class="n">head</span><span class="p">()))</span>
<span class="nb">print</span><span class="p">(</span><span class="n">sample</span><span class="p">)</span>

<span class="c1"># 10. Feature Importance</span>
<span class="n">importance</span> <span class="o">=</span> <span class="n">dt_model</span><span class="o">.</span><span class="n">feature_importances_</span>
<span class="n">feature_importance</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">({</span>
    <span class="s1">&#39;Feature&#39;</span><span class="p">:</span> <span class="n">X</span><span class="o">.</span><span class="n">columns</span><span class="p">,</span>
    <span class="s1">&#39;Importance&#39;</span><span class="p">:</span> <span class="n">importance</span>
<span class="p">})</span><span class="o">.</span><span class="n">sort_values</span><span class="p">(</span><span class="s1">&#39;Importance&#39;</span><span class="p">,</span> <span class="n">ascending</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Feature Importance:&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">feature_importance</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Accuracy: 0.9555555555555556

Classification Report:
                 precision    recall  f1-score   support

    Iris-setosa       1.00      1.00      1.00        19
Iris-versicolor       1.00      0.85      0.92        13
 Iris-virginica       0.87      1.00      0.93        13

       accuracy                           0.96        45
      macro avg       0.96      0.95      0.95        45
   weighted avg       0.96      0.96      0.96        45
</pre></div>
</div>
<img alt="_images/8294911fcd6bc3246569e26ef98540d941cfec8c40e48a0704786630897d34a3.png" src="_images/8294911fcd6bc3246569e26ef98540d941cfec8c40e48a0704786630897d34a3.png" />
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Contoh prediksi pada 5 data test:
    sepal length sepal width petal length petal width       True Class  \
73             A           A            A           B  Iris-versicolor   
18             A           B            B           A      Iris-setosa   
118            B           C            D           D   Iris-virginica   
78             A           A            A           B  Iris-versicolor   
76             D           A            A           B  Iris-versicolor   

     Predicted Class  
73   Iris-versicolor  
18       Iris-setosa  
118   Iris-virginica  
78   Iris-versicolor  
76   Iris-versicolor  

Feature Importance:
        Feature  Importance
3   petal width    0.959975
2  petal length    0.040025
1   sepal width    0.000000
0  sepal length    0.000000
</pre></div>
</div>
</div>
</div>
</section>
</section>
<section id="klasifikasi-data-dengan-data-asli-data-yang-belum-di-diskritisasi-menggunakan-metode-naive-baiyes-dan-decision-tree">
<h2>klasifikasi data dengan data asli(data yang belum di diskritisasi) menggunakan metode naive baiyes dan decision tree<a class="headerlink" href="#klasifikasi-data-dengan-data-asli-data-yang-belum-di-diskritisasi-menggunakan-metode-naive-baiyes-dan-decision-tree" title="Link to this heading">#</a></h2>
<section id="id1">
<h3>klasifikasi dengan naive baiyes<a class="headerlink" href="#id1" title="Link to this heading">#</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span>
<span class="kn">from</span> <span class="nn">sklearn.naive_bayes</span> <span class="kn">import</span> <span class="n">GaussianNB</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">classification_report</span><span class="p">,</span> <span class="n">accuracy_score</span>

<span class="c1"># Load data</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">&#39;iris-full.csv&#39;</span><span class="p">)</span>

<span class="c1"># Pisahkan fitur dan target</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">df</span><span class="p">[[</span><span class="s1">&#39;sepal length&#39;</span><span class="p">,</span> <span class="s1">&#39;sepal width&#39;</span><span class="p">,</span> <span class="s1">&#39;petal length&#39;</span><span class="p">,</span> <span class="s1">&#39;petal width&#39;</span><span class="p">]]</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;Class&#39;</span><span class="p">]</span>

<span class="c1"># Bagi data menjadi training dan testing set</span>
<span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.3</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>

<span class="c1"># Buat dan latih model Naive Bayes</span>
<span class="n">nb_model</span> <span class="o">=</span> <span class="n">GaussianNB</span><span class="p">()</span>
<span class="n">nb_model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>

<span class="c1"># Prediksi pada data test</span>
<span class="n">y_pred</span> <span class="o">=</span> <span class="n">nb_model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>

<span class="c1"># Evaluasi model</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Naive Bayes Classification&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;=&quot;</span><span class="o">*</span><span class="mi">50</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Accuracy: </span><span class="si">{</span><span class="n">accuracy_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span><span class="w"> </span><span class="n">y_pred</span><span class="p">)</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Classification Report:&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">classification_report</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">))</span>

<span class="c1"># Contoh prediksi</span>
<span class="n">sample</span> <span class="o">=</span> <span class="n">X_test</span><span class="o">.</span><span class="n">head</span><span class="p">()</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
<span class="n">sample</span><span class="p">[</span><span class="s1">&#39;True Class&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">y_test</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
<span class="n">sample</span><span class="p">[</span><span class="s1">&#39;Predicted Class&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">y_pred</span><span class="p">[:</span><span class="mi">5</span><span class="p">]</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Contoh Prediksi:&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">sample</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Naive Bayes Classification
==================================================
Accuracy: 0.9778

Classification Report:
                 precision    recall  f1-score   support

    Iris-setosa       1.00      1.00      1.00        19
Iris-versicolor       1.00      0.92      0.96        13
 Iris-virginica       0.93      1.00      0.96        13

       accuracy                           0.98        45
      macro avg       0.98      0.97      0.97        45
   weighted avg       0.98      0.98      0.98        45


Contoh Prediksi:
     sepal length  sepal width  petal length  petal width       True Class  \
73            6.1          2.8           4.7          1.2  Iris-versicolor   
18            5.7          3.8           1.7          0.3      Iris-setosa   
118           7.7          2.6           6.9          2.3   Iris-virginica   
78            6.0          2.9           4.5          1.5  Iris-versicolor   
76            6.8          2.8           4.8          1.4  Iris-versicolor   

     Predicted Class  
73   Iris-versicolor  
18       Iris-setosa  
118   Iris-virginica  
78   Iris-versicolor  
76   Iris-versicolor  
</pre></div>
</div>
</div>
</div>
</section>
<section id="id2">
<h3>klasifikasi dengan decision tree<a class="headerlink" href="#id2" title="Link to this heading">#</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span>
<span class="kn">from</span> <span class="nn">sklearn.tree</span> <span class="kn">import</span> <span class="n">DecisionTreeClassifier</span><span class="p">,</span> <span class="n">plot_tree</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">classification_report</span><span class="p">,</span> <span class="n">accuracy_score</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>

<span class="c1"># Load data</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">&#39;iris-full.csv&#39;</span><span class="p">)</span>

<span class="c1"># Pisahkan fitur dan target</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">df</span><span class="p">[[</span><span class="s1">&#39;sepal length&#39;</span><span class="p">,</span> <span class="s1">&#39;sepal width&#39;</span><span class="p">,</span> <span class="s1">&#39;petal length&#39;</span><span class="p">,</span> <span class="s1">&#39;petal width&#39;</span><span class="p">]]</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;Class&#39;</span><span class="p">]</span>

<span class="c1"># Bagi data menjadi training dan testing set</span>
<span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.3</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>

<span class="c1"># Buat dan latih model Decision Tree</span>
<span class="n">dt_model</span> <span class="o">=</span> <span class="n">DecisionTreeClassifier</span><span class="p">(</span><span class="n">max_depth</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>
<span class="n">dt_model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>

<span class="c1"># Prediksi pada data test</span>
<span class="n">y_pred</span> <span class="o">=</span> <span class="n">dt_model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>

<span class="c1"># Evaluasi model</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Decision Tree Classification&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;=&quot;</span><span class="o">*</span><span class="mi">50</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Accuracy: </span><span class="si">{</span><span class="n">accuracy_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span><span class="w"> </span><span class="n">y_pred</span><span class="p">)</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Classification Report:&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">classification_report</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">))</span>

<span class="c1"># Visualisasi pohon keputusan</span>
<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">15</span><span class="p">,</span><span class="mi">8</span><span class="p">))</span>
<span class="n">plot_tree</span><span class="p">(</span><span class="n">dt_model</span><span class="p">,</span>
          <span class="n">feature_names</span><span class="o">=</span><span class="n">X</span><span class="o">.</span><span class="n">columns</span><span class="p">,</span>
          <span class="n">class_names</span><span class="o">=</span><span class="n">y</span><span class="o">.</span><span class="n">unique</span><span class="p">(),</span>
          <span class="n">filled</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
          <span class="n">rounded</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;Decision Tree Visualization&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>

<span class="c1"># Feature importance</span>
<span class="n">importance</span> <span class="o">=</span> <span class="n">dt_model</span><span class="o">.</span><span class="n">feature_importances_</span>
<span class="n">feature_importance</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">({</span>
    <span class="s1">&#39;Feature&#39;</span><span class="p">:</span> <span class="n">X</span><span class="o">.</span><span class="n">columns</span><span class="p">,</span>
    <span class="s1">&#39;Importance&#39;</span><span class="p">:</span> <span class="n">importance</span>
<span class="p">})</span><span class="o">.</span><span class="n">sort_values</span><span class="p">(</span><span class="s1">&#39;Importance&#39;</span><span class="p">,</span> <span class="n">ascending</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Feature Importance:&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">feature_importance</span><span class="p">)</span>

<span class="c1"># Contoh prediksi</span>
<span class="n">sample</span> <span class="o">=</span> <span class="n">X_test</span><span class="o">.</span><span class="n">head</span><span class="p">()</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
<span class="n">sample</span><span class="p">[</span><span class="s1">&#39;True Class&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">y_test</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
<span class="n">sample</span><span class="p">[</span><span class="s1">&#39;Predicted Class&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">y_pred</span><span class="p">[:</span><span class="mi">5</span><span class="p">]</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Contoh Prediksi:&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">sample</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Decision Tree Classification
==================================================
Accuracy: 1.0000

Classification Report:
                 precision    recall  f1-score   support

    Iris-setosa       1.00      1.00      1.00        19
Iris-versicolor       1.00      1.00      1.00        13
 Iris-virginica       1.00      1.00      1.00        13

       accuracy                           1.00        45
      macro avg       1.00      1.00      1.00        45
   weighted avg       1.00      1.00      1.00        45
</pre></div>
</div>
<img alt="_images/0a76247e673c4f4425f8549017fc12c516da64cc2ec97920f0e9df37209a1655.png" src="_images/0a76247e673c4f4425f8549017fc12c516da64cc2ec97920f0e9df37209a1655.png" />
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Feature Importance:
        Feature  Importance
2  petal length    0.925108
3   petal width    0.074892
1   sepal width    0.000000
0  sepal length    0.000000

Contoh Prediksi:
     sepal length  sepal width  petal length  petal width       True Class  \
73            6.1          2.8           4.7          1.2  Iris-versicolor   
18            5.7          3.8           1.7          0.3      Iris-setosa   
118           7.7          2.6           6.9          2.3   Iris-virginica   
78            6.0          2.9           4.5          1.5  Iris-versicolor   
76            6.8          2.8           4.8          1.4  Iris-versicolor   

     Predicted Class  
73   Iris-versicolor  
18       Iris-setosa  
118   Iris-virginica  
78   Iris-versicolor  
76   Iris-versicolor  
</pre></div>
</div>
</div>
</div>
</section>
</section>
<section id="perbandingan-performa-atara-model-naive-baiyes-dan-decision-tree-untuk-klasifikasi-data-yang-sudah-di-diskritisasi">
<h2>perbandingan performa atara model naive baiyes dan decision tree  untuk klasifikasi data yang sudah di diskritisasi<a class="headerlink" href="#perbandingan-performa-atara-model-naive-baiyes-dan-decision-tree-untuk-klasifikasi-data-yang-sudah-di-diskritisasi" title="Link to this heading">#</a></h2>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>

<span class="c1"># Data aktual dari hasil evaluasi</span>
<span class="n">metrics</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;Accuracy&#39;</span><span class="p">,</span> <span class="s1">&#39;Precision&#39;</span><span class="p">,</span> <span class="s1">&#39;Recall&#39;</span><span class="p">,</span> <span class="s1">&#39;F1-Score&#39;</span><span class="p">]</span>
<span class="n">nb_scores</span> <span class="o">=</span> <span class="p">[</span><span class="mf">0.9556</span><span class="p">,</span> <span class="mf">0.95</span><span class="p">,</span> <span class="mf">0.95</span><span class="p">,</span> <span class="mf">0.95</span><span class="p">]</span>  <span class="c1"># macro avg</span>
<span class="n">dt_scores</span> <span class="o">=</span> <span class="p">[</span><span class="mf">0.9778</span><span class="p">,</span> <span class="mf">0.97</span><span class="p">,</span> <span class="mf">0.98</span><span class="p">,</span> <span class="mf">0.97</span><span class="p">]</span>  <span class="c1"># macro avg</span>

<span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">metrics</span><span class="p">))</span>
<span class="n">width</span> <span class="o">=</span> <span class="mf">0.35</span>

<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>
<span class="n">rects1</span> <span class="o">=</span> <span class="n">ax</span><span class="o">.</span><span class="n">bar</span><span class="p">(</span><span class="n">x</span> <span class="o">-</span> <span class="n">width</span><span class="o">/</span><span class="mi">2</span><span class="p">,</span> <span class="n">nb_scores</span><span class="p">,</span> <span class="n">width</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Naive Bayes&#39;</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;skyblue&#39;</span><span class="p">,</span> <span class="n">edgecolor</span><span class="o">=</span><span class="s1">&#39;grey&#39;</span><span class="p">)</span>
<span class="n">rects2</span> <span class="o">=</span> <span class="n">ax</span><span class="o">.</span><span class="n">bar</span><span class="p">(</span><span class="n">x</span> <span class="o">+</span> <span class="n">width</span><span class="o">/</span><span class="mi">2</span><span class="p">,</span> <span class="n">dt_scores</span><span class="p">,</span> <span class="n">width</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Decision Tree&#39;</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;lightgreen&#39;</span><span class="p">,</span> <span class="n">edgecolor</span><span class="o">=</span><span class="s1">&#39;grey&#39;</span><span class="p">)</span>

<span class="c1"># Formatting</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s1">&#39;Scores&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">12</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;Perbandingan Performa Model Klasifikasi Iris&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">14</span><span class="p">,</span> <span class="n">pad</span><span class="o">=</span><span class="mi">20</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_xticks</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_xticklabels</span><span class="p">(</span><span class="n">metrics</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">11</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">prop</span><span class="o">=</span><span class="p">{</span><span class="s1">&#39;size&#39;</span><span class="p">:</span> <span class="mi">11</span><span class="p">},</span> <span class="n">framealpha</span><span class="o">=</span><span class="mf">0.9</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="s1">&#39;y&#39;</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s1">&#39;--&#39;</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.7</span><span class="p">)</span>

<span class="c1"># Fungsi untuk label nilai</span>
<span class="k">def</span> <span class="nf">autolabel</span><span class="p">(</span><span class="n">rects</span><span class="p">):</span>
    <span class="k">for</span> <span class="n">rect</span> <span class="ow">in</span> <span class="n">rects</span><span class="p">:</span>
        <span class="n">height</span> <span class="o">=</span> <span class="n">rect</span><span class="o">.</span><span class="n">get_height</span><span class="p">()</span>
        <span class="n">ax</span><span class="o">.</span><span class="n">annotate</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;</span><span class="si">{</span><span class="n">height</span><span class="si">:</span><span class="s1">.3f</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">,</span>
                    <span class="n">xy</span><span class="o">=</span><span class="p">(</span><span class="n">rect</span><span class="o">.</span><span class="n">get_x</span><span class="p">()</span> <span class="o">+</span> <span class="n">rect</span><span class="o">.</span><span class="n">get_width</span><span class="p">()</span> <span class="o">/</span> <span class="mi">2</span><span class="p">,</span> <span class="n">height</span><span class="p">),</span>
                    <span class="n">xytext</span><span class="o">=</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">5</span><span class="p">),</span>
                    <span class="n">textcoords</span><span class="o">=</span><span class="s2">&quot;offset points&quot;</span><span class="p">,</span>
                    <span class="n">ha</span><span class="o">=</span><span class="s1">&#39;center&#39;</span><span class="p">,</span>
                    <span class="n">va</span><span class="o">=</span><span class="s1">&#39;bottom&#39;</span><span class="p">,</span>
                    <span class="n">fontsize</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span>
                    <span class="n">bbox</span><span class="o">=</span><span class="nb">dict</span><span class="p">(</span><span class="n">boxstyle</span><span class="o">=</span><span class="s1">&#39;round,pad=0.2&#39;</span><span class="p">,</span> <span class="n">fc</span><span class="o">=</span><span class="s1">&#39;white&#39;</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.7</span><span class="p">))</span>

<span class="n">autolabel</span><span class="p">(</span><span class="n">rects1</span><span class="p">)</span>
<span class="n">autolabel</span><span class="p">(</span><span class="n">rects2</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">ylim</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mf">1.15</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>

<span class="c1"># Tambah watermark</span>
<span class="n">fig</span><span class="o">.</span><span class="n">text</span><span class="p">(</span><span class="mf">0.95</span><span class="p">,</span> <span class="mf">0.05</span><span class="p">,</span> <span class="s1">&#39;Iris Dataset&#39;</span><span class="p">,</span>
         <span class="n">fontsize</span><span class="o">=</span><span class="mi">12</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;gray&#39;</span><span class="p">,</span>
         <span class="n">ha</span><span class="o">=</span><span class="s1">&#39;right&#39;</span><span class="p">,</span> <span class="n">va</span><span class="o">=</span><span class="s1">&#39;bottom&#39;</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.5</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/2c3ffa97c4a95d35e60fa1112aa0ab1c3dfe1d10d9e84f7feb42499e2126cefa.png" src="_images/2c3ffa97c4a95d35e60fa1112aa0ab1c3dfe1d10d9e84f7feb42499e2126cefa.png" />
</div>
</div>
</section>
<section id="perbandingan-performa-atara-model-naive-baiyes-dan-decision-tree-untuk-klasifikasi-data-original">
<h2>perbandingan performa atara model naive baiyes dan decision tree  untuk klasifikasi data original<a class="headerlink" href="#perbandingan-performa-atara-model-naive-baiyes-dan-decision-tree-untuk-klasifikasi-data-original" title="Link to this heading">#</a></h2>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>

<span class="c1"># Data untuk visualisasi</span>
<span class="n">metrics</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;Accuracy&#39;</span><span class="p">,</span> <span class="s1">&#39;Precision&#39;</span><span class="p">,</span> <span class="s1">&#39;Recall&#39;</span><span class="p">,</span> <span class="s1">&#39;F1-Score&#39;</span><span class="p">]</span>
<span class="n">nb_scores</span> <span class="o">=</span> <span class="p">[</span><span class="mf">0.9556</span><span class="p">,</span> <span class="mf">0.95</span><span class="p">,</span> <span class="mf">0.95</span><span class="p">,</span> <span class="mf">0.95</span><span class="p">]</span>  <span class="c1"># macro avg</span>
<span class="n">dt_scores</span> <span class="o">=</span> <span class="p">[</span><span class="mf">0.9778</span><span class="p">,</span> <span class="mf">0.97</span><span class="p">,</span> <span class="mf">0.98</span><span class="p">,</span> <span class="mf">0.97</span><span class="p">]</span>  <span class="c1"># macro avg</span>

<span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">metrics</span><span class="p">))</span>
<span class="n">width</span> <span class="o">=</span> <span class="mf">0.35</span>

<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>
<span class="n">rects1</span> <span class="o">=</span> <span class="n">ax</span><span class="o">.</span><span class="n">bar</span><span class="p">(</span><span class="n">x</span> <span class="o">-</span> <span class="n">width</span><span class="o">/</span><span class="mi">2</span><span class="p">,</span> <span class="n">nb_scores</span><span class="p">,</span> <span class="n">width</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Naive Bayes&#39;</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;skyblue&#39;</span><span class="p">)</span>
<span class="n">rects2</span> <span class="o">=</span> <span class="n">ax</span><span class="o">.</span><span class="n">bar</span><span class="p">(</span><span class="n">x</span> <span class="o">+</span> <span class="n">width</span><span class="o">/</span><span class="mi">2</span><span class="p">,</span> <span class="n">dt_scores</span><span class="p">,</span> <span class="n">width</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Decision Tree&#39;</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;lightgreen&#39;</span><span class="p">)</span>

<span class="n">ax</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s1">&#39;Scores&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;Perbandingan Performa Model Klasifikasi&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_xticks</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_xticklabels</span><span class="p">(</span><span class="n">metrics</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>

<span class="c1"># Tambah label nilai di atas bar</span>
<span class="k">def</span> <span class="nf">autolabel</span><span class="p">(</span><span class="n">rects</span><span class="p">):</span>
    <span class="k">for</span> <span class="n">rect</span> <span class="ow">in</span> <span class="n">rects</span><span class="p">:</span>
        <span class="n">height</span> <span class="o">=</span> <span class="n">rect</span><span class="o">.</span><span class="n">get_height</span><span class="p">()</span>
        <span class="n">ax</span><span class="o">.</span><span class="n">annotate</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;</span><span class="si">{</span><span class="n">height</span><span class="si">:</span><span class="s1">.3f</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">,</span>
                    <span class="n">xy</span><span class="o">=</span><span class="p">(</span><span class="n">rect</span><span class="o">.</span><span class="n">get_x</span><span class="p">()</span> <span class="o">+</span> <span class="n">rect</span><span class="o">.</span><span class="n">get_width</span><span class="p">()</span> <span class="o">/</span> <span class="mi">2</span><span class="p">,</span> <span class="n">height</span><span class="p">),</span>
                    <span class="n">xytext</span><span class="o">=</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span>  <span class="c1"># 3 points vertical offset</span>
                    <span class="n">textcoords</span><span class="o">=</span><span class="s2">&quot;offset points&quot;</span><span class="p">,</span>
                    <span class="n">ha</span><span class="o">=</span><span class="s1">&#39;center&#39;</span><span class="p">,</span> <span class="n">va</span><span class="o">=</span><span class="s1">&#39;bottom&#39;</span><span class="p">)</span>

<span class="n">autolabel</span><span class="p">(</span><span class="n">rects1</span><span class="p">)</span>
<span class="n">autolabel</span><span class="p">(</span><span class="n">rects2</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">ylim</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mf">1.1</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/9bca6a77d3271e31a249b2d61c35aa3e40ecaf951e4968e05859e1f9ed544df2.png" src="_images/9bca6a77d3271e31a249b2d61c35aa3e40ecaf951e4968e05859e1f9ed544df2.png" />
</div>
</div>
</section>
<section id="kesimpulan-visualisasi-performa-model-klasifikasi-pada-dataset-iris">
<h2>üìä Kesimpulan Visualisasi Performa Model Klasifikasi pada Dataset Iris<a class="headerlink" href="#kesimpulan-visualisasi-performa-model-klasifikasi-pada-dataset-iris" title="Link to this heading">#</a></h2>
<section id="perbandingan-naive-bayes-vs-decision-tree">
<h3>üîç Perbandingan Naive Bayes vs Decision Tree<a class="headerlink" href="#perbandingan-naive-bayes-vs-decision-tree" title="Link to this heading">#</a></h3>
<p>Dari dua grafik visualisasi yang membandingkan performa model <strong>Naive Bayes</strong> dan <strong>Decision Tree</strong> pada <strong>data original</strong> dan <strong>data yang telah didiskritisasi menggunakan K-Means</strong>, diperoleh beberapa insight menarik:</p>
</section>
<hr class="docutils" />
<section id="data-asli-kontinu">
<h3>üü¶ Data Asli (Kontinu)<a class="headerlink" href="#data-asli-kontinu" title="Link to this heading">#</a></h3>
<div class="pst-scrollable-table-container"><table class="table">
<thead>
<tr class="row-odd"><th class="head"><p>Metric</p></th>
<th class="head"><p>Naive Bayes</p></th>
<th class="head"><p>Decision Tree</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>Accuracy</p></td>
<td><p>0.9556</p></td>
<td><p><strong>0.9778</strong></p></td>
</tr>
<tr class="row-odd"><td><p>Precision</p></td>
<td><p>0.9500</p></td>
<td><p><strong>0.9700</strong></p></td>
</tr>
<tr class="row-even"><td><p>Recall</p></td>
<td><p>0.9500</p></td>
<td><p><strong>0.9800</strong></p></td>
</tr>
<tr class="row-odd"><td><p>F1-Score</p></td>
<td><p>0.9500</p></td>
<td><p><strong>0.9700</strong></p></td>
</tr>
</tbody>
</table>
</div>
<ul class="simple">
<li><p><strong>Decision Tree</strong> unggul pada semua metrik.</p></li>
<li><p>Naive Bayes tetap kompetitif, tetapi lebih sensitif terhadap nilai numerik yang berdekatan.</p></li>
</ul>
</section>
<hr class="docutils" />
<section id="data-diskret-diskretisasi-dengan-k-means">
<h3>üü© Data Diskret (Diskretisasi dengan K-Means)<a class="headerlink" href="#data-diskret-diskretisasi-dengan-k-means" title="Link to this heading">#</a></h3>
<div class="pst-scrollable-table-container"><table class="table">
<thead>
<tr class="row-odd"><th class="head"><p>Metric</p></th>
<th class="head"><p>Naive Bayes</p></th>
<th class="head"><p>Decision Tree</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>Accuracy</p></td>
<td><p>0.9556</p></td>
<td><p><strong>0.9778</strong></p></td>
</tr>
<tr class="row-odd"><td><p>Precision</p></td>
<td><p>0.9500</p></td>
<td><p><strong>0.9700</strong></p></td>
</tr>
<tr class="row-even"><td><p>Recall</p></td>
<td><p>0.9500</p></td>
<td><p><strong>0.9800</strong></p></td>
</tr>
<tr class="row-odd"><td><p>F1-Score</p></td>
<td><p>0.9500</p></td>
<td><p><strong>0.9700</strong></p></td>
</tr>
</tbody>
</table>
</div>
<ul class="simple">
<li><p>Setelah diskretisasi, <strong>hasilnya relatif stabil</strong> ‚Äî tidak terjadi penurunan performa signifikan.</p></li>
<li><p>Menariknya, <strong>Decision Tree tetap unggul</strong> meski data telah diubah menjadi kategori.</p></li>
</ul>
</section>
<hr class="docutils" />
<section id="kesimpulan-akhir">
<h3>‚úÖ Kesimpulan Akhir<a class="headerlink" href="#kesimpulan-akhir" title="Link to this heading">#</a></h3>
<ul class="simple">
<li><p><strong>Decision Tree consistently outperforms Naive Bayes</strong> dalam semua kondisi.</p></li>
<li><p><strong>Diskretisasi dengan K-Means</strong> tidak merugikan performa model secara signifikan ‚Äî bahkan bisa membantu jika fitur numerik terlalu bervariasi atau tidak terstandarisasi.</p></li>
<li><p>Naive Bayes <strong>lebih cocok untuk data kategorikal</strong>, namun dalam kasus ini, performanya masih sedikit di bawah Decision Tree.</p></li>
</ul>
</section>
<hr class="docutils" />
<section id="rekomendasi">
<h3>üìå Rekomendasi<a class="headerlink" href="#rekomendasi" title="Link to this heading">#</a></h3>
<ul class="simple">
<li><p>Untuk data seperti Iris yang memiliki struktur yang jelas dan fitur yang cukup informatif, <strong>Decision Tree menjadi pilihan lebih unggul</strong>.</p></li>
<li><p><strong>Diskretisasi bisa dipertimbangkan</strong> untuk keperluan interpretabilitas atau saat bekerja dengan model seperti Naive Bayes, tanpa mengorbankan akurasi secara signifikan.</p></li>
</ul>
</section>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./."
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

                </article>
              

              
              
              
              
                <footer class="prev-next-footer d-print-none">
                  
<div class="prev-next-area">
    <a class="left-prev"
       href="decision_tree.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title">üå≥ Penjelasan tentang Decision Tree &amp; Information Gain</p>
      </div>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">


  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#pendahuluan">üåü Pendahuluan</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#apa-itu-diskretisasi">üîç Apa itu Diskretisasi?</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#manfaat-diskretisasi">‚ú® Manfaat Diskretisasi:</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#langkah-langkah-eksperimen">üß≠ Langkah-Langkah Eksperimen</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#mengubah-data-iris-menjadi-kategorikal-diskretisasi">1. üì• Mengubah Data Iris Menjadi Kategorikal (Diskretisasi)</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#klasifikasi-data-asli-dan-data-diskret">2. ü§ñ Klasifikasi Data Asli dan Data Diskret</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#membandingkan-performa-model">3. üìä Membandingkan Performa Model</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#kesimpulan-yang-diharapkan">üéØ Kesimpulan yang Diharapkan</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#clustering-untuk-class-sepal-lenght">clustering untuk class sepal lenght</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#menggabungkan-data-hasil-cluster-dengan-data-original">menggabungkan data hasil cluster dengan data original</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#clustering-untuk-clas-sisa">clustering untuk clas sisa</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#klasifikasi-data-yang-sudah-di-diskritisasi-dengan-menggunakan-metode-naive-baiyes-dan-decision-tree">klasifikasi data yang sudah di diskritisasi dengan menggunakan metode naive baiyes dan decision tree</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#klasifikasi-dengan-naive-baiyes">klasifikasi dengan naive baiyes</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#klasifikasi-dengan-decision-tree">klasifikasi dengan decision tree</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#klasifikasi-data-dengan-data-asli-data-yang-belum-di-diskritisasi-menggunakan-metode-naive-baiyes-dan-decision-tree">klasifikasi data dengan data asli(data yang belum di diskritisasi) menggunakan metode naive baiyes dan decision tree</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id1">klasifikasi dengan naive baiyes</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id2">klasifikasi dengan decision tree</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#perbandingan-performa-atara-model-naive-baiyes-dan-decision-tree-untuk-klasifikasi-data-yang-sudah-di-diskritisasi">perbandingan performa atara model naive baiyes dan decision tree  untuk klasifikasi data yang sudah di diskritisasi</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#perbandingan-performa-atara-model-naive-baiyes-dan-decision-tree-untuk-klasifikasi-data-original">perbandingan performa atara model naive baiyes dan decision tree  untuk klasifikasi data original</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#kesimpulan-visualisasi-performa-model-klasifikasi-pada-dataset-iris">üìä Kesimpulan Visualisasi Performa Model Klasifikasi pada Dataset Iris</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#perbandingan-naive-bayes-vs-decision-tree">üîç Perbandingan Naive Bayes vs Decision Tree</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#data-asli-kontinu">üü¶ Data Asli (Kontinu)</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#data-diskret-diskretisasi-dengan-k-means">üü© Data Diskret (Diskretisasi dengan K-Means)</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#kesimpulan-akhir">‚úÖ Kesimpulan Akhir</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#rekomendasi">üìå Rekomendasi</a></li>
</ul>
</li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By Dicky Saputra calon data analyst
</p>

  </div>
  
  <div class="footer-item">
    

  <p class="copyright">
    
      ¬© Copyright 2023.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b"></script>
<script src="_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>